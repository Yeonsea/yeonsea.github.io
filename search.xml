<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Elasticsearch概览]]></title>
    <url>%2F2019%2F09%2F10%2FElasticsearch%E6%A6%82%E8%A7%88%2F</url>
    <content type="text"><![CDATA[入门全文搜索引擎基于 Lucene 构建的开源、分布式、RESTful接口 ^1 Github 的搜索是基于 Elasticsearch 构建的，只索引项目主分支，但包括20亿个索引文档，30TB的索引文件 Shay Banon 失业开发者 给妻子构建食谱搜索引擎 早期版本的 Lucene 为方便Java可以在应用中增加搜索功能 第一个开源项目“Compass” 重写 Compass 使其成为一个独立的项目，Elasticsearch 横向可扩展 分片机制提供更好的分布性：sharding，类似 HDFS 的块机制 高可用：replica 使用简单 Lucene：最初由 Doug Cutting 开发 倒排索引 基础知识术语概念 索引词：term 文本：text 分析：Analysis 集群：Cluster 节点：node 路由：routing 分片：shard 主分片：primary shard 副本分片：replica shard 副本：replica 索引：index 索引是具有相同结构的文档集合 类型：type 类型是索引的逻辑分区 文档：document 存储的一个 JSON 格式的字符串 映射：mapping 字段：field 开源字段：source field 主键：ID 每个 Elasticsearch 分片是一个 Lucene 的索引，有文档存储数量限制 JSON 轻量级数据交换格式 对外接口curlREST：REpresentational State Transfer 表述性状态传输 一种约定 简化沟通成本 索引索引管理 创建 删除 获取 打开 关闭 索引映射管理 增加映射 获取索引 索引别名 过滤索引别名 删除别名 查询现有的别名 索引配置 更新索引配置 获取配置 索引分析 索引模板 索引模板就是创建好一个索引参数设置 settings 和 映射 mapping 的模板，在创建新索引的时候指定模板名称就可以使用模板定义好的参数设置和映射 创建 删除 获取 复制配置 重建索引 索引监控 索引统计 索引分片 索引恢复 索引分片存储 状态管理 清除缓存 索引刷新 冲洗 合并索引 文档管理 增加文档 更新删除 查询 多文档操作 索引词频率 查询更新接口 映射映射是定义存储和索引文档以及字段的过程 字段数据类型 元字段 映射参数 动态映射：在 Elasticsearch 中可以不事先建好索引结构，在使用的时候可以直接插入文档到索引。 搜索深入搜索搜索方式 URL 搜索 GET方式 POST 请求参数搜索 排序 sort 数据列过滤 脚本支持重新评分对短语进行重新评分，然后再查询滚动查询请求Elasticsearch 提供了滚动 API 来解决此问题，这有点像数据库中的游标隐藏内容查询inner hits 嵌套结构相关搜索函数 Preference 搜索分片副本执行偏好设置 索引加权 index_boost 最小分值 min_score 分值解释 explain 可以使每个命中的查询解释它的得分是如何计算出来的 分片情况查询 _search_shards 总分查询 _count 是否存在查询 验证接口搜索模板查询DSLDomain-specific LanguageElasticsearch 提供了基于 JSON 的完整查询 DSL 来定义查询全文搜索 布尔查询 短语查询 短语前缀查询 多字段查询 Lucene 语法查询 简化查询字段查询 单字段查询 多字段查询 范围查询复合查询 常数得分查询 布尔查询 最大值获取查询 boosting 查询 指定索引查询 过滤查询 限制查询- 连接查询 嵌套查询 父子文档查询地理查询Elasticsearch 支持两种地理数据类型的字段：地理点类型，支持经度纬度对；地理形状类型，支持点、线、圈、多边形、多边形集合等。 地理形状查询 地理范围查询 地理距离查询 地理距离范围查询 多边形地理查询 地理散列单元查询跨度查询 索引词跨度查询 多索引词跨度查询 首跨度查询 接近跨度查询 或跨度查询 非跨度查询 包含跨度查询 内部跨度查询高亮显示Elasticsearch 中的高亮显示是来源于 Lucene 的功能，允许一个或者多个字段上突出显示搜索内容简化查询catAPI常用简化查询指标 indices nodes recovery thread pool 聚合聚合分类度量聚合 平均值聚合 基数聚合 最大值聚合 最小值聚合 和聚合 值基数聚合 统计聚合 百分比聚合 百分比分级聚合 最高命中排行聚合 脚本度量聚合 地理边界聚合 地理重心聚合 分组聚合 子聚合 直方图聚合 日期直方图聚合 时间范围聚合 范围聚合 过滤聚合 多重过滤聚合 空值聚合 嵌套聚合 采样聚合 重要索引词聚合 索引词聚合 总体聚合 地理点距离聚合 地理散列网格聚合 IPv4 范围聚合管道聚合 平均分组聚合 移动平均聚合 总和分组聚合 总和累计聚合 最大分组聚合 最小分组聚合 统计分组聚合 百分位分组聚合 差值聚合 分组脚本聚合 串行差分聚合 分组选择器聚合 集群管理集群节点监控 对 Elasticsearch 监控的API 主要有三类：一类是集群相关的，以_cluster开头，第二类是监控节点相关的，以_nodes开头，第三类是任务相关的，以_tasks开头 集群健康值 集群状态 集群统计 集群任务管理 待定集群任务 节点信息 节点统计 集群分片迁移 移动 remove 取消 cancel 分配 allocate 集群配置更新集群节点配置 主节点 主要职责是和集群操作相关的内容，如创建或删除索引，跟踪哪些节点是集群的一部分，并决定哪些分片分配给相关的节点。 数据节点 主要是存储索引数据的节点，主要对文档进行增删改查、聚合操作等。 客户端节点 当主节点和数据节点配置都设置为 false 时，该节点只能处理路由请求，处理搜索，分发索引操作等，从本质上来说该客户端节点表现为智能负载平衡器。独立的客户端节点在一个比较大的集群中是非常有用的，它协调主节点和数据节点，客户端节点加入集群可以得到集群的状态，根据集群的状态可以直接发送路由请求。 部落节点 部落节点可以跨越多个集群，它可以接收每个集群的状态，然后合并成一个全局集群的状态，它可以读写所有节点上的数据。节点发现 ping 模块 单播模块主节点选举在集群中，系统会自动通过 ping 来进行选举节点或者加入主节点，这些都是自动完成的。故障检测集群平衡配置 分片分配设置 基于磁盘的配置 分片智能分配 分片配置过滤 其他集群配置索引分词器分词器的概念分词器analyzer的作用是当一个文档被索引的时候，分词器从文档中提取出若干词元token来支持索引的存储和搜索。 分词器 是由一个分解器 tokenizer、零个或多个词元过滤器 token filters 组成。 中文分词器 smartcn IKAnanlyzer插件 java 插件 jar 站点插件 js html css 混合插件插件管理正常情况下插件位于$ES_HOME/bin 下通过rpm等安装的位置可能会不同插件安装 查询插件 删除插件 Silent/Verbose 参数 更多调试信息 自定义配置目录 超时设置 代理设置 自定义插件目录 强制插件 插件清单 API 插件 报警插件 分词插件 发现插件 管理和站点插件 高级配置 在Elasticsearch 的配置中，主要有两种配置方式，一种是静态配置，另一种是动态配置。静态配置的参数只能在配置文件中事先写好，动态配置的参数可以通过_cluster/settings进行设置。 网络相关配置 本地网关配置 HTTP 配置 网络配置 常用网络配置，高级网络配置，高级TCP配置，传输和HTTP协议 传输配置 TCP传输，本地传输，传输追踪脚本配置 脚本使用 脚本配置 索引脚本，启用动态脚本，脚本自动重载，本地java脚本，lucene表达式脚本，得分，文档字段，保存的字段，在脚本中访问文档的得分，源字段，Groovy内置方法快照和恢复配置 只读仓库 快照 恢复 快照状态线程池配置线程池类型 cached 线程池是一个无限的线程池，如果存在挂起的请求时，就会产生一个线程。这个线程池用来防止提交的请求被阻塞或丢弃。 fixed 线程池拥有固定大小的线程来操作队列中的请求（任意界限）直到请求没有线程提供服务。size参数控制线程的数量，queue_size 参数可以控制没有线程执行的请求队列的大小。默认设置为-1，意味着无限大。当请求到达而且队列已经满了，请求会被终止。 scaling 线程池拥有动态数量的线程。线程的数量与工作量成正比，并且在1和size参数值之间变化。keep_alive参数决定一个线程的空闲时间。 处理器设置处理器的数量是自动检测的，线程池的设置会基于结果自动设置。有时，处理器的数量会被错误检测，在这种情况下，处理器的数量可以使用 processes进行明确设置。 索引配置 索引模块是控制每个索引指标的模块。索引模块包括分词、分片控制和分配、字段映射、索引相似性配置、慢查询记录、文件系统配置、控制事务和刷新模块。 缓存配置 总内存控制 列数据内存控制 请求内存控制 数据缓存 节点查询缓存 索引缓冲区 分片请求缓存 索引恢复 TTL区间索引分片分配 碎片分配过滤 延迟分配 每个节点的总碎片合并 一个 Elasticsearch 分片就是一个 Lucene 索引，Lucene索引被分解为分片。分片是索引的内部存储单元，存储索引数据并且是不变的。周期性合并(merge)小的分片为更大的分片来保持索引大小在范围内。 相似模块 配置相似性 可用的相似性模块响应慢日志监控 搜索慢日志 索引慢日志存储支持存储类型 simplefs 简单文件系统类型 niofs NIO 文件系统类型 mmapfs MMap 文件系统类型在文件系统上通过映射文件到内存(mmap)存储分片索引 default_fs 默认类型是 NIO FS 和 MMapFS 的混合，对每个类型的文件选择最佳文件系统事务日志 冲洗设置 事务日志设置 告警、监控和权限管理告警Watcher 是进行警告和通知的插件，可以根据数据的变化采取行动。它的设计原理是在 Elasticsearch 中执行查询，满足条件的情况下，产生告警。 安装结构 Trigger Inputs Condition Transform Action告警输出配置告警输出可以为邮件、Webhook、Logging、HipChat、Slack、PagerDuty告警管理 列出警告 删除警告监控 Marvel 是商业监控方案，用来监控 Elasticsearch 集群历史状态的有力工具，便于性能优化以及故障诊断。监控主要分为六个层面，分别是集群层、节点层、索引层、分片层、事件层、Sense。 安装配置 监控参数配置 监控索引配置 Kibana 配置相关 Tribe 部落节点监控配置权限管理 Shield 是商业权限管理插件，它可以保护 Elasticsearch 中的数据，采用加密的通信密码，基于角色的访问控制，IP过滤和审计等。 工作原理Shield 是 Elasticsearch 的一个插件，一旦安装完成，插件将会拦截所有 API 请求，然后对请求进行认证和授权的校验。该插件同时提供 SSL 安全协议来传输网络数据，该插件提供了审计日志记录的能力，用来进行验证和审计。 用户认证 授权 节点认证和信道加密 IP 过滤 审计用户认证用户认证方式 Native 一个内置的本地认证系统，默认可用 File 一种内置的基于文件的认证系统，默认可用 LDAP 通过外部轻量级目录协议进行身份验证 AD 通过外部活动目录服务的身份验证 PKI 通过使用可信的X.509证书的认证匿名用户访问角色管理 增加角色 查看角色 删除角色 ELK 应用 Logstash 是一个灵活的开放源码的数据收集、处理、传输的工具。Logstash 可以处理日志、事件、非结构化的数据，并把它们输出出来，包括可以输出到 Elasticsearch 中。 Kibana 是一个开源的数据可视化平台，可以把数据以强大的图形化方式展示出来。从柱状图到地图等，它可以通过多个图表的组合来生成更为强大的仪表面板，帮助人们理解、分析和分享数据。 Logstash配置配置文件的结构配置文件由输入，过滤，输出三部分组成，每部分都是由插件构成的，这些插件负责处理日志的不同过程 事件相关配置 每个事件都有不同的属性，比如 apache 的访问日志，可以包括状态码、协议、路径、客户端 IP等，在 Logstash 中这些属性叫做 fields。由于它们是事件属性，所以这些配置选项只会在过滤器和输出块中工作。 插件管理插件管理器通过 bin/logstash-plugin 的脚本来管理整个插件的生命周期，通过命令行接口(CLI)调用可以安装、卸载、升级插件。 输入插件 过滤插件 输出插件 编解码插件Kibana 配置安装比较简单，也是绿色的，解压后直接运行默认端口 5601。Discover 新的搜索 保存搜索加载保存的搜索 自动刷新 查看字段数据统计Visualize视图是定制可视化报表的地方 选择一个图标类型 选择一个数据源 可视化编辑器配置 保存编辑器Dashboard仪表盘是用一组原始图标根据需要组合成一个丰富的图形报表 空仪表盘 创建仪表盘 保存仪表盘 加载仪表盘 共享仪表盘Settings 索引设置 管理字段 告警设置 Kibana 服务器配置 管理搜索，可视化仪表板Elasticsearch 5.0 的特性与改进]]></content>
  </entry>
  <entry>
    <title><![CDATA[关于分布式系统的稳定性]]></title>
    <url>%2F2019%2F08%2F25%2F%E5%85%B3%E4%BA%8E%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%A8%B3%E5%AE%9A%E6%80%A7%2F</url>
    <content type="text"><![CDATA[日志分析信息 堆栈信息 访问用户 IP、请求 URL、应用响应时间 内存回收信息 自定义信息 应用 通过异常堆栈，可以定位到谁宕机了 产生问题的程序行，对异常进行修复 访问 IP 和请求参数，排查是否遭到攻击，以及攻击的形式 应用的响应时间、垃圾回收以及系统 load 来判断系统负载，是否要增加机器 线程 dump，判断是否死锁及线程阻塞的原因 应用的 GC 日志，对系统代码和 JVM 内存参数进行优化，减少 GC 次数与 stop the world 时间，优化应用响应时间 集群监控木桶原理 监控指标 load：linux 中，可以通过 top,uptime来查看系统load值，系统load定义为特定时间间隔内运行队列中的平均线程数。 cpu 利用率 磁盘剩余空间 网络 traffic 磁盘 IO 内存使用 qps query per second rt response time select/ps update/ps、delete/ps GC JVM 虚拟机开发团队一直致力于消除或者减少工作线程因内存回收而导致的停顿，用户线程的停顿时间在不断地缩短，但是仍然没办法完全消除 心跳检测 对于自治的分布式系统而言，一般都有一整套的集群心跳检测机制，能够实时地移除掉宕机的 Slave，避免路由规则将任务分配给已宕机的机器来处理。而如果是 Master 宕机，集群能够自动地进行 Master 的选举，从而避免由 Master 宕机而导致整个集群不能提供服务的情况发生，这一类系统，如 ZooKeeper，便是一个很好的典范。也有一部分系统可以通过外部干预，使备份机器 stand by，或者是双机互为备份，以实现故障切换，如 MySQL、Nginx等，以避免单点故障的发生。 具体操作： ping 应用层检测 curl 定时访问应用中预留的自检 url 业务检测 可在 response 的 header 中约定一个值，来标识返回的结果是否正常 容量评估及应用水位当前水位 = 当前总 qps / （单台机器极限 x 机器数）x 100% 流量控制流量控制实施多个维度 对系统的总并发请求数进行限制 - 可以很好地控制系统的负载，避免出现流量突增将系统压垮的情况 限制单位时间内的请求次数（如限制qps） - 限制调用频次，防止某个外部调用的流量突增影响到服务本身的稳定性 通过白名单机制来限制每一个接入系统调用的频率等 超载的部分流量 直接返回，显示系统繁忙 通过单机内存队列来进行有限的等待 通过分布式消息队列来将用户的请求异步化 服务稳定性依赖管理服务消费日志 优雅降级 对于调用超时的非核心服务，可以设定一个阈值，如果调用超时的次数超过这个阈值，便自动将该服务降级。此时服务调用者跳过对该服务的调用，并指定一个休眠的时间点，当时间点过了以后，再次对该服务进行重试，如果服务恢复，则取消降级，否则继续保持该服务的降级状态，直到所依赖的服务故障恢复。 服务分级开关 当系统负载较高，即将突破警戒水位时，如何通过实时地屏蔽一些非核心链路的调用来降低系统的负载呢？这时需要系统预先定义一些开关控制程序的服务提供策略。开关通过修改一些预先定义好的全局变量，来控制系统的关键路径和逻辑。 应急预案高并发系统设计 高并发系统与普通系统设计的区别在于，既要保障系统的可用性和可扩展性，又要兼顾数据的一致性，还要处理多线程同步的问题。任何细微问题，都有可能在高并发环境下被无限地放大，直至系统宕机 操作原子性 原子操作指的是不可分割的操作，它要么执行成功，要么执行失败，不会产生中间状态。原子操作也是一些常见的多线程程序bug的源头。并发相关的问题对于测试来说，并不是每次都能重现，因此处理起来十分棘手。JDK5.0 以后开始提供 Atomic Class，支持 CAS compare and set 等一系列原子操作，来帮助我们简化多线程程序设计。数据count统计 CountDownLatch是做减法，CyclicBarrier是做加法,Semaphor的临界资源可以反复使用 CountDownLatch不能重置计数，CycliBarrier提供的reset()方法可以重置计数，不过只能等到第一个计数结束。Semaphor可以重复使用。 CountDownLatch和CycliBarrier不能控制并发线程的数量，Semaphor可以实现控制并发线程的数量。AtomicInteger compareAndSet 方法 调用 Unsafe 对象的 native 方法 compareAndSwapInt 方法，最终通过 Atomic::com::(x, addr, e)来实现原子操作 数据库的事务操作数据库事务具有 ACID 属性导致事务失败的原因有很多： 修改不符合表的约束规则 网络异常 存储介质故障 为了实现数据库状态的恢复，DBMS 系统通常需要维护事务日志以追踪事务中所有影响数据库数据的操作，以便执行失败时进行事务的回滚。事务日志可以提高事务执行的效率，存储引擎只需要将修改行为持久到事务日志当中，便可以只对该数据在内存中的拷贝进行修改，而不需要每次修改都将数据回写到磁盘。日志写入是一小块区域的顺序IO，而数据库数据的磁盘回写则是随机IO，磁头需要不停地移动来寻找需要更新数据的位置。 多线程同步多线程同步指的是线程之间执行的顺序，多个线程并发地访问和操作同一数据，并且执行的结果与访问或者操作的次序有关。 synchronized ReentrantLock ReentrantLock 的好处是，等待是可以中断的。通过 tryLock(timeout, unit)，可以尝试获得锁，并且指定等待时间。另一个特性是可以在构造 ReentrantLock 时使用公平锁，公平锁指的是多个线程在等待同一个锁时，必须按照申请锁的先后顺序依次获得锁。synchronized 中的锁是非公平的，默认情况下 ReentrantLock 也是非公平的，但是可以在构造函数中指定使用公平锁。对于 ReentrantLock 来说，还有一个十分实用的特性，它可以同时绑定多个 condition 条件，以实现更精细化的同步控制。 数据一致性分布式系统常常通过复制数据来提高系统的可靠性和容错性，并且将数据的副本存放到不同的机器上。由于多个副本的存在，使得维护副本一致性的代价很高。因此，许多分布式系统都采用弱一致性或者最终一致性，来提高系统的性能和吞吐能力。 最终一致性是弱一致性的一种特殊形式，这种情况下系统保证用户最终能够读取到某个操作对系统的更新，“不一致性窗口”的时间依赖于网络的延迟、系统的负载和副本的个数。最终一致性举例： mysql 主从数据同步 zookeeper 的 leader election 和 atomic broadcas 系统可扩展性系统的可扩展性也成为可伸缩性，是一种对软件系统计算处理能力的评价指标。只需要增加相应的机器，便能够使性能平滑地提升。水平扩展相对于硬件的垂直扩展来说，对于软件设计的能力要求更高，系统设计更复杂，但却能够使系统处理能力几乎可以无限制扩展系统的可扩展性也会受到一些因素的制约，CAP理论指出，系统的一致性、可用性和可扩展性三个要素对于分布式系统来说，很难同时满足。因此，在系统设计时，往往得做一些取舍。 并发减库存秒杀活动杜绝网络投机者使用工具导致不公平竞争：加速验证码，复杂验证码。 数据一致性问题： 对于高并发访问的浏览型系统来说，单机数据库如不进行扩展，往往很难支撑。因此常常会采用分库技术来提高数据库的并发能力，并且通过使用分布式缓存技术，将磁盘磁头的机械运动化为内存的高低电平，以降低数据库的压力，加快后端的响应速度。响应的越快，线程释放的也越快，能够支持的单位时间内的查询数qps也越高，并发处理能力就越强。带来的问题是跨数据库或者是分布式缓存与数据库之间难以进行事务操作。为了避免数据不一致的情况发生，并且保证前端页面能够在高并发情况下正常浏览，可以采用实际库存和浏览库存分离的方式。mysql 中 myisam 是表锁策略，innodb 是行锁策略，innodb 更适合高并发写入的场景 一个线程获得行锁以后，其他并发线程就需要等待它处理完成，这样系统将无法利用多线程并发执行的优势，并且随着并发数的增加，等待的线程会越来越多，rt 急剧飙升，最终导致可用连接数被占满，数据库拒绝服务。 可以通过将一行库存拆分成多行，便可以解除行锁导致的并发资源利用的问题。路由策略：id取模，随机。 性能优化如何寻找性能的瓶颈 Web 性能优化涉及前端优化、服务端优化、操作系统优化、数据库查询优化、JVM调优等众多领域的知识寻找可优化的点是第一步也是最重要的一步，也就是所谓的性能瓶颈，性能瓶颈实际上就是木桶原理中最短的那一块木板 前端优化工具 YSlow页面响应时间方法响应时间Java 环境下有一个十分有效的动态跟踪工具，btrace GC日志分析 GC 日志能够反应出 Java 应用执行内存回收详细情况，如 Minor GC 的频繁程度、Full GC 的频繁程度、GC 所导致应用停止响应的时间、引起 GC 的原因等。在 JVM 启动时加上几个参数1-verbose:gc -Xloggc:/gc.log -XX:+PrintGCDetails -XX:+PrintGCDataStamps 分别表示日志存放位置，输出 GC 详情，输出 GC 时间戳 CMS 收集器是一款以获取最短回收停顿时间为目的的收集器，它是基于标记清除算法实现的，整个过程大致分为四个步骤： CMS initial mark, CMS concurrent mark, CMS remark, CMS concurrent sweep 数据库查询low_slow_querylow_query_time通过 MySQL 的配置文件 my.cnf ，可以修改慢查询日志的相关配置 系统资源使用性能测试工具性能测试指的是通过一些自动化的测试工具模拟多种正常、峰值，以及异常负载对系统的各项性能指标进行测试。 ab全称为 ApacheBench，专门针对 HTTP 服务器进行性能测试的小工具，可以模拟多个并发请求来对服务器进行压力测试，得出服务器在高负载下能够支持的qps及应用的响应时间，为系统设计者提供参考依据。 Apache JMeter开源性能测试工具，比 ab 更为强大，采用纯 Java 实现，支持多种协议的性能基准测试，如HTTP,SOAP,FTP,TCP,SMTP,POP3等。提供了图形化界面 Tomcat 在启动脚本中加入如下配置，便能通过jconsole,VisualVM等工具查看系统相关信息1CATALINA\_OPTS=&quot;$CATALINA_OPTS -Djava.rmi.server.hostname=***.***.***.*** -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=**** -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false&quot; HP LoadRunner商业付费，更成熟，更强大，支持的协议更为广泛，用户体验更高。 反向代理引流 在分布式环境下，流量真正到达服务器之前，一般会经过负载均衡设备进行转发，通过修改负载均衡的策略，可以改变后端服务器所承受的压力。 Nginx 配置权重，新版本灰度发布。 TCPCopy网易技术部2011年9月开源的一个项目，请求复制工具，能够将在线请求复制到测试机器，模拟真实环境，达到程序在不上线的情况下承担线上真实流量的效果。 性能优化措施前端性能优化 页面的 HTTP 请求数量 新建一个到服务器的HTTP连接需要重新经历TCP协议握手建立连接状态等过程，并且大部分请求和响应都包含了很多相同 header 与 cookie 内容，增加了网络带宽消耗。因此，减少 HTTP 请求的数量能够加速页面的加载，在不改变页面外观的情况下，可以通过采取合并样式和脚本文件等措施，来减少页面加载所需要请求数。 是否使用 CDN 网络 CDN 网络使得用户能够就近取得所需要的资源，降低静态资源传输的网络延迟。可以将图片、样式文件、脚本文件、页面框架等不需要频繁变动的内容推送到 CDN网络，可以提高页面加载的速度。 是否使用压缩 对于前端样式文件与脚本文件，可以将其中空格、注释等不必要的字符去掉，并且通过使用 gzip 压缩来减少网络上传输的字节数。当然，压缩也是有成本的，它会消耗一定的 CPU 资源，但通常情况下来说这种开销都是值得的。 Java 程序优化单例对于 IO 处理、数据库连接、配置文件解析加载等一些非常耗费系统资源的操作，我们必须对这些实例的创建进行限制，或者始终使用一个公用的实例，以节约系统开销，这种情况下就需要用到单例模式。 Future 模式假设一个任务执行起来需要花费一些时间，为了省去不必要的等待时间，可以先获取一个提货单，即 Future ，然后继续处理别的任务，直到货物到达，即任务执行完得到结果，此时便可以用提货单进行提货，即通过 Future 对象得到返回值。1234567891011121314151617public class TestFuture &#123; static class Job&lt;Object&gt; implements Callable&lt;Object&gt; &#123; @Override public Object call() throws Exception &#123; return loadData(); &#125; &#125; public static void main(String[] args) throws Exception &#123; FutureTask future = new FutureTask(new Job&lt;Object&gt;()); new Thread(future).start(); // do something else Object result = (Object) future.get(); &#125;&#125; FutureTask 类实现了 Future 和 Runnable 接口，FutureTask 开始后，loadData()执行时间可能较长，因此可以先处理其他事情，等其他事情处理好以后，再通过 future.get() 来获取结果，如果 loadData() 还未执行完毕，则此线程会阻塞等待。 线程池使用线程池将互不依赖的几个动作切分，通过多线程对串行工作进行改进，将成倍地提高工作效率。12345678910111213141516171819public class TestExecutorService &#123; static class Job implements Runnable &#123; @Override public void run() &#123; doWork(); // 具体工作 &#125; public void doWork() &#123; System.out.println(&quot;doing...&quot;); &#125; &#125; public static void main(String[] args) &#123; ExecutorService exec = Executors.newFixedThreadPool(5); for (int i = 0; i &lt; 10; i ++) &#123; exec.execute(new Job()); &#125; &#125;&#125; 选择就绪 JDK自1.4起开始提供全新的 IO 编程类库，简称 NIO，其不但引入了全新高效的 Buffer 和 Channel ，同时还引入了基于 Selector 的非阻塞 IO 机制，将多个异步的 IO 操作集中到一个或几个线程当中进行处理。使用 NIO 代替阻塞 IO 能提高程序的并发吞吐能力，降低系统的开销。 对于每一个请求，单独开一个线程进行响应的逻辑处理，如果客户端的数据传递并不是一直进行，而是断断续续的，则相应线程需要 IO 等待，并进行上下文切换。 Selector 机制使得线程不必等待客户端的 IO 就绪，当客户端还没就绪时，可以处理其他请求，提高了服务器的并发吞吐能力，降低了资源消耗。 减少上下文切换进程上下文切换会有一定的调度开销，这个过程中操作系统和JVM会消耗一定的CPU周期，并且由于CPU处理器会缓存一部分数据，当新线程被切换进来时，它所需要的数据可能不在CPU缓存中，因此还会导致CPU缓存的命中率下降。 降低锁竞争降低锁竞争的一种有效的方式是尽可能地缩短锁持有的时间，比如可以将一部分与锁无关的代码移出同步代码块，特别是执行起来开销较大的操作，以及可能使当前线程被阻塞的操作。另一种减小锁持有时间的方式是减小锁的粒度，将原先使用单独锁来保护的多个变量变为采用多个相互独立的锁分别进行保护，这样就能够降低线程请求锁的几率，从而减少竞争发生的可能性。当然，使用的锁越多，发生死锁的风险也就越高。第三种降低锁竞争的方式就是放弃使用独占锁，而使用其他更友好的并发方式来保障数据的同步，原子变量就是使用读写锁。对于多读少写的情况，使用读写锁能够比使用独占锁提供更高的并发数量。 压缩在进行数据传输之前，可以先将数据进行压缩，以减少网络传输的字节数，提升数据传输的速度。接收端可以将数据进行解压，以还原出传递的数据，并且经过压缩的数据还可以节约所耗费的存储介质(磁盘或内存)的空间与网络带宽，降低成本。当然，压缩需要大量的CPU计算，并且根据压缩算法的不同，计算的复杂度和数据的压缩比也存在较大差异。 结果缓存本地缓存，分布式缓存 数据库查询性能优化以mysql为例 合理使用索引 对于使用B树或B+树存储的组合索引来说，有一个最基本的原则，即“最左前缀”的原则，如果查询不是按照索引的最左列来开始查询，则无法使用到组合索引。 反范式设计范式设计好处: 冗余数据的减少，无疑节约了存储空间，而且保证了关系的一致性; 由于冗余数据的减少，当数据需要进行更新时，要修改的数据则变少了，这样会提升更新操作的速度; 范式化的表通常更小，可以更好地利用表的查询缓存来提高查询速度。但是，对于大多数复杂的业务场景来说，数据表现的纬度不可能是单表的。因此在进行查询操作时，需要进行表的关联。这不仅代价高昂，由于查询条件指定的列可能并不在同一个表中，因此也无法使用到索引，这将导致数据库的性能严重下降。 为了尽可能地避免关联查询带来的性能损耗，有人提出了反范式设计，即将一些常用的需要关联查询的列进行冗余存储，以便减少表关联带来的随机IO和全盘扫描。 使用查询缓存 query_cache_type query_cache_size query_cache_limit 使用搜索引擎 在分布式环境下，为了便于数据库扩展，提高并发处理能力，相关联的表可能并不在同一个数据库当中，而是分布在多个库当中，并且表也可能已经进行了切分，无法进行复杂的条件查询。这时候就需要搭建搜索引擎，将需要进行查询和展现的列通过一定的规则都建到索引当中，以提供复杂的垮表查询与分组操作。 使用 key-value 数据库 对于保有海量数据的互联网企业来说，多表的关联查询是非常忌讳的。出于性能的考虑，更多时候往往根据表的主键来进行查询，或者进行简单的条件查询。因此，SQL的功能被很大程度地弱化了。 GC 优化Parallel Scavenge 垃圾收集器是悲观策略，每次晋升到 OldGen 的平均大小如果大于当前OldGen的剩余空间，则触发一次FullGC。如果频繁发生，可以通过-Xmx与-Xms参数来调整整个堆的大小，以增加OldGen的大小，YoungGen对应的-Xmn保持不变。默认情况下，CMS收集器的垃圾回收会在OldGen使用了68%空间时被激活，可以调大。但如果预留的内存无法满足程序需要，则会出现 concurrent mode failure。 堆设置： Xms 是指程序启动时初始内存大小（此值可以设置成与-Xmx相同，以避免每次GC完成后 JVM 内存重新分配）。 Xmx 指程序运行时最大可用内存大小，程序运行中内存大于这个值会 OutOfMemory。 Xmn 年轻代大小（整个JVM内存大小 = 年轻代 + 年老代 + 永久代）。 XX:NewRatio 年轻代与年老代的大小比例，-XX:NewRatio=4 设置为4，则年轻代与年老代所占比值为1：4。 XX:SurvivorRatio 年轻代中Eden区与Survivor区的大小比值，-XX:SurvivorRatio=4，设置为4，则两个Survivor区与一个Eden区的比值为 2:4 XX:MaxPermSize 设置永久代大小。 XX:MaxTenuringThreshold 设置垃圾最大年龄。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。 Xss 设置每个线程的堆栈大小。 硬件提升性能内存越大越好，硬盘读写，避免网卡成为系统吞吐的瓶颈，CPU核数。 Java 应用故障排查常用工具 jps 类似 linux 的 ps jstat 对虚拟机各种运营状态进行监控的工具，通过它可以查看虚拟机的类加载与卸载情况，管理内存使用和垃圾收集等信息，监视JIT即时编译器的运行情况等。 jinfo 用于查看应用程序的配置参数，以及打印运行JVM时所指定的JVM参数。 jstack 用来生成虚拟机当前的线程快照信息，线程快照就是当前虚拟机每一个线程正在执行的方法堆栈的集合。 jmap 查看等待回收对象的队列，查看堆的概要信息，包括采用的是哪种GC收集器，堆空间的使用情况，以及通过JVM参数指定的各个内存空间的大小。 BTrace 是一个开源的 Java 程序动态跟踪工具。基本原理是通过Hotspot虚拟机的HotSwap技术将跟踪的代码动态替换到被跟踪的Java程序内，以观察程序运行的细节。通过BTrace脚本，可以在方法执行时，输出传递给方法的参数与方法的返回值。 JConsole 是一款JDK内置的图形化性能分析工具，它可以用来连接本地或者远程正在运行的JVM，对运行的Java应用程序的性能及资源消耗情况进行分析和监控，并提供可视化的图表对相关数据进行展现。 Memory Analyzer Eclipse 插件 VisualVM 功能强大的 all-in-one 工具]]></content>
      <tags>
        <tag>调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Writing & Publishing your First NPM Package]]></title>
    <url>%2F2019%2F08%2F23%2FWriting%26Publishing_your_First_NPM_Package%2F</url>
    <content type="text"><![CDATA[Just do itNPM account Create an NPM account if you don’t yet have onenpm js. Open terminal and … 1npm adduser ** If you use taobao mirror, it will show 403 Forbidden. Then …123npm config get registry # show the current login sourcenpm config set registry=http://registry.npmjs.org # change to the npmjsnpm login # relogin Create a component1module.exports.*** = *** Create a new repository on GitHubInit and publishUnder the component, open the terminal init1234567code .git initgit add .git commit -m &quot;first commit&quot;git remote add origin https://github.com/***/***.gitgit push -u origin mastersudo git push -u origin master publish1npm publish Use it!create a new projectimport12npm i ** --saveparser index.html]]></content>
      <tags>
        <tag>Front-end</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[西尔维斯特-矩阵]]></title>
    <url>%2F2019%2F08%2F19%2F%E8%A5%BF%E5%B0%94%E7%BB%B4%E6%96%AF%E7%89%B9-%E7%9F%A9%E9%98%B5%2F</url>
    <content type="text"><![CDATA[西尔维斯特（James Joseph Sylvester, 1814~1897） 1数量可以用二维数据表格来展示 打猎得到的各种猎物和税金之间的关系可以用两个二维数据表格来表示 00 兔子 鹿 野猪 西尔维斯特 5只 1只 0只 东健 2只 0只 1只 小彬 0只 0只 2只 猎物 税金 兔子 20韩元 鹿 50韩元 野猪 100韩元 运动器械和自行车的价格与需要购买的数量之间的关系可以用两个二维数据表格来表示 2把数字或字母在括号内排列成二维数据表格就叫作矩阵。矩阵的各个数字或字母叫作元素。横向叫作行，纵向叫作列。 矩阵的行数为m，列数为n时，矩阵的大小为m*n，行数和列数数目相等的矩阵叫作方块矩阵。 元素都为0的矩阵叫作零矩阵；主对角线元素都为1，其余元素都是0的矩阵叫作单位矩阵。 3把方程组变成矩阵来解，可以进行一下运算： 某一行可以乘以一个常数：相当于一个方程的两边同时乘以一个常数。 某一行乘以一个常数后可以与另一行相加：相当于一个方程的两边同时乘以一个常数后再与另一个方程相加。 行与行可以对调：方程的顺序对调后，解不变。 4方程组$$\begin{cases} ax+by=p \\ cx+dy=q\end{cases}$$用矩阵表达式如下$$\begin{pmatrix} a &amp; b \\ c &amp; d\end{pmatrix}\begin{pmatrix} x \\ y\end{pmatrix}=\begin{pmatrix} p \\ q\end{pmatrix}$$可以简单表示为$$\begin{pmatrix} a &amp; b &amp;: &amp;p \\ c &amp; d &amp;: &amp;q\end{pmatrix}$$ 矩阵的某一行乘以一个常数后形成的新矩阵，求出的解是同一个方程组的解。 矩阵的某一行乘以一个常数后与另一行相加形成的新矩阵，求出的解是同一个方程组的解。 方程组构成的矩阵，行与行可以对调，对调后方程组的解不变。 5可以将下面的三元一次方程组变成矩阵来解$$\begin{cases} a_{11}x+a_{12}y+a_{13}z=p \\ a_{21}x+a_{22}y+a_{23}z=q \\ a_{31}x+a_{32}y+a_{33}z=r\end{cases}$$ $$\begin{pmatrix} a_{11} &amp; a_{12} &amp; a_{13} &amp;: &amp;p \\ a_{21} &amp; a_{22} &amp; a_{23} &amp;: &amp;q \\ a_{31} &amp; a_{32} &amp; a_{33} &amp;: &amp;r\end{pmatrix}$$ 6两个矩阵相等是指两个矩阵中所有的元素对应相等。 两个矩阵之间对应的元素相加，可以实现两个矩阵之间的加法运算。 一个矩阵的各元素可以乘以某个常数。 两个矩阵之间对应的元素相减，可以实现两个矩阵之间的减法运算。 7两个矩阵相乘，前面矩阵的列数要与后面矩阵的行数相等。这时乘积的大小由前面矩阵的行数和后面矩阵的列数决定。即$$A_{m×n}B_{n×t}=C_{m×t}$$ 前面矩阵的第i行和后面矩阵的第j列的各对应元素的乘积之和，构成乘积矩阵中的(i, j)元素。 寻找日常生活中可以用矩阵乘积表示的问题。 8可求出方块矩阵$$\begin{pmatrix} a &amp; b \\ c &amp; d\end{pmatrix}$$的逆矩阵 $${\begin{pmatrix} a &amp; b \\ c &amp; d\end{pmatrix}}^{-1}= {1 \over ad - bc}\begin{pmatrix} d &amp; -b \\ -c &amp; a\end{pmatrix}(ad-bc \ne 0)$$ 利用逆矩阵求二元一次方程组$$\begin{cases} ax+by=p \\ cx+dy=q\end{cases}$$的解。首先像下面这样用矩阵表示方程：$$\begin{pmatrix} a &amp; b \\ c &amp; d\end{pmatrix}\begin{pmatrix} x \\ y\end{pmatrix}=\begin{pmatrix} p \\ q\end{pmatrix}$$然后式子两边靠左的位置写上$$\begin{pmatrix} a &amp; b \\ c &amp; d\end{pmatrix}$$的逆矩阵，再做乘法运算。$$\begin{pmatrix} x \\ y\end{pmatrix}={\begin{pmatrix} a &amp; b \\ c &amp; d\end{pmatrix}}^{-1}\begin{pmatrix} p \\ q\end{pmatrix}$$-- $$\begin{pmatrix} x \\ y\end{pmatrix}={1 \over ad - bc}\begin{pmatrix} d &amp; -b \\ -c &amp; a\end{pmatrix}\begin{pmatrix} p \\ q\end{pmatrix}={1 \over ad - bc}\begin{pmatrix} dp-bq \\ -cp+aq\end{pmatrix}(ad-bc \ne 0)$$-- $$x={dp-bq \over ad-bc}, y={-cp+aq \over ad-bc}$$ 9研究是否可以用矩阵表示身边的实际问题。思考如何确定一个矩阵的各个元素。 利用矩阵解决问题，预测未来 各列元素的和等于1的矩阵用俄国数学家马尔可夫的名字命名为马尔可夫转移矩阵。这个矩阵经常用来表示某种变化的概率，某个地区的人口变化、市场经济的版图变化等，我们周围的各种变化都可以用这样的矩阵表示，帮助我们有效地解决问题。 老鼠房间概率城市邻接矩阵]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>Basic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[布隆过滤器]]></title>
    <url>%2F2019%2F03%2F12%2F%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%2F</url>
    <content type="text"><![CDATA[布隆过滤器什么是布隆过滤器布隆过滤器是一种基于概率进行验重的数据结构。它的基本原理是：小概率事件不容易同时发生。 布隆过滤器使用多个哈希函数把同一个字符串转换成多个不同的哈希值，并记录这些哈希值的特征。下次再面对一个字符串时，布隆过滤器再次使用这些哈希函数把这个字符串转换为多个哈希值。如果这个哈希值全部符合原先那个字符串对应的各个哈希值的特征，则认为这两个字符串是相同的。 哈希函数哈希算法不是一种加密算法，而是一种不可逆的摘要算法。不同的哈希函数可实现不同的哈希算法。使用同一个哈希算法，能够把同一个字符串转成同一个哈希值。 1234import hashlibcode = 'hello'result = hashlib.sha256(code.encode()).hexdigest()print(result) 结果是一个十六进制的_数_ 布隆过滤器的原理 假设K个哈希函数，对同一个字符串计算哈希值，得到K个完全不同的哈希值。 让这K个哈希值同时除以一个数M，就可以得到K个余数。 对于一个新的字符串，重复这个过程，如果新字符串获得的K个余数与原来的字符串对应的K个余数完全相同，那么就可以说，这两个字符串”很有可能”是同一个字符串。 $$1-(1-e^{\frac{-KN}{M}})^{K}$$ 如何压缩数据容量采用二进制保存数字 布隆过滤器与Redis结合使用Redis字符串的位操作，记录K个余数的位置即可。 布隆过滤器的弊端布隆过滤器只能单向验证重复。随着Redis字符串对应的二进制位越来越多的为被设置为1，布隆过滤器误报的概率越来越大，因为可能其它多个字符串对应的二进制位中越来越多的位被设置为1，其中K个值刚好和一个新来的字符串的K个余数重合。提前规划好数据规模与容忍的误报率。 最多需要对 n 个字符串进行验证重复操作，能够容忍的最大误报率为 p，那么，布隆过滤器将会使用到的二进制位的数量为： $$m = -\frac{n\ln{p}}{\ln{2}^{2}}$$ 哈希函数的个数为： $$k = \frac{m}{n}\ln{2}$$]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用 Spring Boot 编写 RESTful API]]></title>
    <url>%2F2018%2F12%2F23%2F%E7%94%A8SpringBoot%E7%BC%96%E5%86%99RESTfulAPI%2F</url>
    <content type="text"><![CDATA[课程课程 开始一个最简单的RESTFul API项目RESTful APIRepresentational State Transfer 所有的东西都是资源，所有的操作都是通过对资源的增删改查（CRUD）实现 对资源的增删改查对应对URL的操作（POST,DELETE,PUT,GET） 无状态的 Spring Boot大量使用注解，减少配置，无需配置XML自带嵌入式web服务器 Mavenpom.xml文件是Maven项目的配置文件几个常用的Maven命令（在pom.xml同级目录下运行）mvn test 编译并运行测试用例mvn spring-boot:run 运行spring-boot项目mvn package 打包项目mvn clean 可以和其它命令一起使用，例如mvn clean package 日期型转JSON格式可以在属性上增加1@JsonFormat(timezone=&quot;GMT+8&quot;, pattern=&quot;yyyy-MM-dd&quot;) 或 1@JsonFormat（shape=JsonFormat.Shape.NUMBER） 全局修改可以在application.yml 123456spring: jackson: date-format: yyyy-MM-dd #如果使用字符串表示，用这行设置格式 timezone: GMT+8 serialization: write-dates-as-timestamps: true #使用数值timestamp表示日期 RestController详解热部署（Hot Swapping）pom中加入devtools 12345678&lt;dependencies&gt; ... &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 记录日志Commons-logging or SLF4j 12private static final Log log = LogFactory.getLog(Xxx.class);private static final Logger log = LoggerFactory.getLogger(Xxx.class); 日志级别：TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATALapplication.yml配置日志12345logging: file: target/app.log level: ROOT: WARN cn.devmgr: TRACE 命令行工具CURL测试工具postman 在RestController中获取各种相关信息的方法 内容 获取方法 URL中路径的一部分 首先需要在RequestMapping做映射，之后在方法中可以通过注解使用映射的变量。可以写多个，@PutMapping(“/{id}/characters/{cId}”)，还可以使用正则表达式限制类型（不符合要求会返回4xx的错误信息，表示请求参数有问题）此例子表示id必须是数字：@PutMapping(“/{id:\\d+}”) POST方法传递过来的JSON 给参数前增加@RequestBody注解，Spring会自动把POST的Request Body部分的JSON转换成方法声明的类。如果转化失败会返回4xx错误，表示请求参数有问题。 POST方法传递的是表单数据 首先声明传入的是application/x-wwww-form-urlencoded的格式，可在RequestMapping增加consumes参数，@PostMapping(value=”/tvseries”, consumes=MediaType.APPLICATION_FORM_URLENCODED_VALUE)，在方法上增加参数，参数使用@RequestParam注解即可，public Object insert(@RequestParam(value=”name”, required=false) String name)，凡是可以通过HttpServletRequest.getParameter(String)方法取到的值，含表单提交的、QueryString附带的，都可以使用@RequestParam注解得到。默认是request=true。 QueryString的参数 使用@RequestParam注解，通过参数获得,例如：public Object query(@RequestParam(value=”page”, required=false) Integer page) Request Header 可以使用@Requestheader注解获取Request的头信息,例如public ResultJSON editCompany(@RequestHeader(“user-agent”) String userAgent) 注意：@RequestHeader后面的头名字不区分大小写，但RequestParam, PathVariable等是区分的。如果RequestHeader后面不写参数，会用后面的变量名替代。 获取cookie值 使用cookieValue注解，和其它类似，除非为了兼容老现有客户端，新API里不建议用cookie。 获取当前的Request Response 直接写参数，例如：public Object doSomething(HttpServletRequest request, HttpServletResponse response) 获取当前用户 直接在方法上增加参数，类型为org.springframework.security.core.Authentication, 例如：public TvSeries deleteOne(Authentication auth)，参数auth内会存储有当前的用户信息。 文件上传 首先要设置consumes为multipart/form-data，@PostMapping(value=”/files”, consumes=MediaType.MULTIPART_FORM_DATA_VALUE),在方法中写参数 public Map&lt;String, Object&gt; uploadFile(@RequestParam(“file”) MultipartFile file)。在方法中可以直接使用MultipartFile中的流保存文件了。 对客户端传入数据的校验原则：不要相信前端传过来的数据；尽量要前端少传递数据 Bean Validation: JSR303, Hibernate Validator Bean Validation 注解：@Null@NotNull@Min@Max@Size@Past 验证Date@Future@AssertTrue 验证Boolean@AssertFalse@Valid 级联验证注解 类型 注解 任何类型 NULL, NotNull 布尔型 AssertTrue, AssertFalse 字符串 NotBlank, Pattern, Size, Email, DecimalMin, Digits 数值 DecimalMax, DecimalMin, Digits, Max, Min, NegativeOrZero, Positive, PositiveOrZero 集合、Map、List NotEmpty, Size 日期 Future, Past, FutureOrPresent, PastOrPresent 以上注解都指Bean Validation 2.0 定义的注解，在javax.validation.constraints包下。Hibernate有些非JSR标准注解和上面的同名但package不同，功能会和上面这些有些细微差异。 约束规则对子类依旧有效groups参数 每个约束用注解都有一个groups参数 可接收多个class类型（必须是接口） 不声明groups参数是默认组javax.validation.groups.Default 声明了groups参数的会从Default组移除，如需加入Default组需要显示声明，例如@Null(groups={Default.class, Step1.class}) @Valid vs @Validated @Valid是JSR标准定义的注解，只验证Default组的约束 @Validated是Spring定义的注解，可以通过参数来指定验证的组，例如：@Validation({Step1.class,Default.class})表示验证Step1和Default两个组的约束 @Valid可用在成员变量上，进行级联验证；@Validated只能用在参数上，表示这个参数需要验证 参数中只用@Validated，通不过校验的参数，不会执行这个方法，加上BindingResult result ，参数通不过校验也会进入方法执行，校验结果会通过result参数传递进来。 手动验证 12345// 装载验证器@Autowired Validator validator;// 验证某个类，下面是执行默认的验证组，如果需要指定验证组，多传一个class参数Set&lt;ConstraintViolation&lt;?&gt;&gt; result = validator.validate(obj);// 通不过校验result的集合会有值，可以通过size()判断 在Spring Boot项目中使用Mybatis程序的层次结构Web前端、App、小程序、其它系统等Web控制层：@RestController @Controller业务逻辑层：@Service数据访问层：@Repository@Component数据库 PBF: Package by Feature 按功能划分PBL: Package by Layer 按层次划分 相邻层次的数据传输 PO：Persistant Object 持久对象 DTO：Data Transfer Object 数据传输对象 VO：Value Object 或 View Object POJO：Pure Old Java Object 或 Plain Ordinary Java Object DO：Domain Object BO：Business Object 处理业务逻辑 DAO：Data Access Object JavaBean: 有一个public的无参构造方法 属性private，且可以通过get、set、is（可以替代get，用在布尔型属性上）方法或遵循特定命名规范的其它方法访问 可序列化，实现Serializable接口 POJO vs JavaBean: POJO比javabean更简单。POJO严格的遵守简单对象的概念，而一些JavaBean中往往会封装一些简单逻辑。 POJO主要用于数据的临时传递，它只能装载数据，作为数据存储的载体，不具有业务逻辑处理能力。 JavaBean虽然数据的获取与POJO一样，但是javabean当中可以有其他方法。 几种简化方案： 一种POJO从web控制层到数据访问层 用JavaBean代替POJO POJO的get,set写起来也麻烦，用public的field代替 添加Mybatis支持步骤 修改pom.xml，添加mybatis支持 修改application.yml添加数据库连接 修改启动类，增加@MappingScan(“package-of-mapping”)注解 添加Mybatis Mapping接口 添加Mapping对应的XML（可选） pom.xml中添加 123456789&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.postgresql&lt;/groupId&gt; &lt;artifactId&gt;postgresql&lt;/artifactId&gt;&lt;/dependency&gt; application.yml中添加 1234567spring: datasource: dbcp2.validation-query: select 1 driverClassName: org.postgresql.Driver url: jdbc:postgresql://127.0.0.1:5432/thedb?stringtype=unspecified username: password: Spring Boot 项目的单元测试Assert-JUnit的断言 判断某条件是否为真 Assert.assertTrue(条件表达式)； 判断某条件是否为假 Assert.assertFalse(条件表达式)； 判断两个变量值是否相同 Assert.assertEquals(val1, val2); 判断两个变量值是否不相同 Assert.assertNotEquals(val1, val2); 判断两个数组是否相同 Assert.assertArrayEquals(数组1, 数组2)； 直接测试失败 Assert.fail() Assert.fail(message) Assert vs assert Assert是JUnit的断言类，全名是org.junit.Assert Assert提供了很多静态方法，例如… assert是java关键字，使用方法有两种，表达式为false时，jvm会退出； assert关键字内表达式是否被检查成立依赖jvm的参数，默认是关闭的 Java命令行参数：-ea (enableassertions) -da (disableassertions 默认) 概念 驱动模块 被测模块 桩模块 使用场景：替代尚未开发完毕的子模块；替代对环境依赖较大的子模块（例如数据访问层）； mockito12345&lt;dependency&gt; &lt;groupId&gt;org.mockito&lt;/groupId&gt; &lt;artifactId&gt;mockito-core&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; TDD Test Driven Development (测试驱动开发) 先写测试用例，后写实现代码 重构现有代码时特别好用 RDD: Resume Driven Development 在 Spring 中管理数据库事务@Transactional name 当在配置文件中有多个TransactionManager,可以用该属性指定选择哪个事务管理器。 propagation 事务的传播行为，默认值为REQUIRED。 isolation 事务的隔离度，默认采用DEFAULT。 timeout 事务的超时时间，默认值为-1,。如果超过该时间限制但事务还没有完成，则自动回滚事务。 readOnly 指定事务是否为只读事务，默认值为false；为了忽略那些不需要事务的方法，比如读取数据，可以设置readOnly为true。 rollbackFor 指定能够触发事务回滚的异常类型。 noRollbackFor 指定的异常类型，不回滚事务 1.noRollbackFor或子类；2.rollbackFor或子类；3.throws定义的异常或子类；4.其它异常；5.无异常 @Transactional(propagation=xx) propagation.REQUIRED 如果有事务，那么加入事务，没有的话新建一个（默认） propagation.NOT_SUPPORTED 容器不为这个方法开启事务 propagation.REQUIRED_NEW 不管是否存在事务，都创建一个新的事务，原来的挂起，新的执行完毕，继续执行老的事务 propagation.MANDATORY 必须在一个已有的事务中执行，否则抛出异常 propagation.NEVER 必须在一个没有的事务中执行，否则抛出异常（与propagation.MANDATORY相反） propagation.SUPPORTS 如果其它bean调用这个方法，在其它bean中声明事务，那就用事务，如果其它bean没有声明事务那就不用事务 propagation.NESTED 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则进行与propagation.REQUIRED类似的操作 @Transactional(isolation=xx) Isolation.READ_UNCOMMITTED 读未提交数据 （脏读、不可重复读、幻读） Isolation.READ_COMMITTED 读已提交数据（不可重复读、幻读） Isolation.REPEATABLE_READ 可重复读 （幻读） Isolation.SERIALIZATION 串行化 Isolation.DEFAULT 使用数据库默认 Isolation vs Lock 两个不同的东西，隔离不是靠锁实现的，是靠对数据的监控实现的。 锁：表加好锁了，除非出现死锁等特殊情况，事务是不会被数据库主动回滚的。 隔离：如果发现数据不符合数据库隔离级别，当前事务会出错并回滚。相比锁被回滚可能性较大，需要程序有出错重试的步骤。 @Transactional注解的timeout参数 timeout事务的超时时间，默认值为-1,。如果超过该时间限制但事务还没有完成，则自动回滚事务。 方法抛出异常，事务被回滚，可能是SQL执行时间过长的异常，也可能是TransactionTimedOutException 从方法执行开始计算，每个SQL执行前检查一次是否超时，方法全部执行完毕后不检查是否超时 Mybatis进阶复杂类的ORMapping和主子表的同时数据插入#{}可转义 ${} 不可转义（可能导致sql注入） 使用TypeHandler处理枚举、数组、JSON等特殊类型EnumTypeHandler vs EnumOrdinalTypeHandler EnumTypeHandler存储的是对应类的名字，可以存储成一个字符串 EnumOrdinalTypeHandler存储的是枚举类型的顺序 ArrayTypeHandler自定义JsonTypeHandler Spring Security安全控制的层级 基于URL的控制 基于方法的控制 程序内 配置Spring Security12345678910111213141516171819@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true, jsr250Enabled = false)public class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; private final static Log log = LogFactory.getLog(WebSecurityConfig.class); @Override protected void configure(HttpSecurity httpSecurity) throws Exception &#123; if (log.isTraceEnabled()) &#123; log.trace(&quot;configure httpSecurity...&quot;); &#125; //默认的spring-security配置会让所有的请求都必须在已登录的状况下访问；下面这段代码禁止了这种操作。 httpSecurity.csrf().disable() .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS).and() .authorizeRequests().anyRequest().permitAll(); &#125;&#125; Spring Security 注解@EnableGlobalMethodSecurity(prePostEnable=true, securedEnable=true, jsr250Enabled=true)prePostEnable=true: @PreAuthorize @PostAuthorize @PreFilter @PostFiltersecuredEnable=true: @Securedjsr250Enable: @RolesRequied (JSR250) @PreAuthorize @PostAuthorize 中常用的表达式 hasRole(‘user’, ‘admin’) hasAnyRole(‘user’, ‘admin’) hasAuthority(‘query’, ‘update’) hasAnyAuthority(‘query’, ‘update’) permitAll denyAll principal, authentication 当前用户 Role vs Authorization ROLE_开头则是role JSR250 RolesAllowed全部要求是role Spring EL中hasRole也要求是role hasAuthority则不用ROLE_开头 Controller内获取当前用户12345public Object doSomething(Authentication auth)&#123; User u = (User) auth.getPrincipal();&#125;或 Authentication auth = SecurityContextHolder.getContext().getAuthentication(); 启用Spring Security1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; OpenId 提供用户追踪方式 无需使用用户名密码登录 协议2.0版提供属性交换功能 目前已经很少使用 OAuth开放授权 目前是OAuth2.0 2.0不兼容1.0 密码无需告诉第三方 为用户提供一个令牌，允许通过令牌访问资源 OAuth 2.0 Grant Types 授权码模式 Authorization Code 简化模式 Implicit 密码模式 Password 客户端模式 Client Credentials Refresh Token JWT JSON Web Token 三部分：Header、Playload、Verify Signature Header：头部信息，声明类型和加密算法 Playload：载荷 Verify Signature：签名，用于验证头部和载荷部分是否被修改过 JWT的加密方式 HMAC 共用一个秘钥 SHA256 公钥私钥分开 生成JWT和验证JWT的jar12345&lt;dependency&gt; &lt;groupId&gt;com.auth0&lt;/groupId&gt; &lt;artifactId&gt;java-jwt&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt;&lt;/dependency&gt; 网站：https://github.com/auth0/java-jwt Spring Async, Scheduling &amp; CacheSpring Async 异步执行配置：@EnableAsync (@SpringBootApplication 那里)使用：@Async （方法上）@Async方法返回值： void Future 其他类型一律返回null；遇到int/double/float/boolean基本类型，执行时会抛出异常：AopInvocationException; Spring Scheduling使用： @EnableScheduling 注解启用Scheduling 方法上加@Scheduled注解，方法会按照参数定期执行@Scheduled 参数： cron 值为字符串 zone 设置时区 fixedDelay (单位毫秒)，每次方法执行完毕后，休息固定时间后再次启动 fixedRate (单位毫秒)按照固定频率启动执行-initialDelay (单位毫秒)，和上面三个参数搭配使用，首次执行延时 集群/负载均衡环境 独立出来一个application运行scheduling task 使用：Quartz Scheduler Spring Cache缓存： 利用java程序中的变量（简单；集群环境中多个实例无法同步） 缓存服务器（Memcached，Redis）Spring中通过注解使用缓存 @EnableCaching启用缓存注解 @Cacheable @CacheEvict @CachePut @CacheConfig 使用 Redis 缓存服务POM中加入依赖 1234&lt;dependecy&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; application.yml 中加入配置 1234567891011spring: cache: redis: time-to-live: 3306 redis: host: localhost port: 6379 pool: max-active: 5 max-idle: 10 max-wait: 10000 Websocket &amp; JMSWebsocket 全双工通道，数据双向传输 浏览器和服务器之间的持久性的连接 比轮询/长轮询大幅节省资源 使用80/443等HTTP端口 ws://example.com/wsapi wss://secure.example.com/ IE10以上浏览器支持 JMS Java Message Service – Java消息服务 在两个应用程序或者分布式服务之间提供异步消息通讯 应用间解耦 企业应用集成中应用较多 消息服务器很多，Apache ActiveMQ是比较常见的一个 JMS消息模式 点对点（P2P）：每个消息有一个生产者一个消费者 发布者/订阅者（Pub/Sub）:每个消息一个生产者、多个消费者 安装ActiveMQ 配置pom文件 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-activemq&lt;/artifactId&gt;&lt;/dependency&gt; 配置application.yml 123spring: activemq: broker-url: tcp://127.0.0.1:61616 @EnableJms 注解 部署Spring Boot项目Spring Profile 和配置日志记录框架 可以设置不同的配置参数 可以设置不同的bean的装载 Active Profile 同时可以有多个被激活的profile 有active和default两个概念 如果没有设置active，则spring使用设置的default，如果没有声明default，则使用那些无显示指定的作为default 生产环境架构性能调优 前端：数据缓存；加载顺序；显示顺序；预先加载； NGINX: 设置客户端缓存；数据压缩传输；HTTP2.0 应用：优化算法；优化SQL（慢SQL）；避免N+1查询；异步操作；使用缓存；不常修改数据的静态化；集群； 数据库：索引和统计信息；优化表结构；冗余列和计算列；表拆分；分区表；统计慢SQL（提供程序）；SQL优化建议；升级硬件； 以服务程序运行（ubuntu）杂项在 Spring Boot 项目中使用Servlet,Filter,Listener等Servlet 1234@WebServlet(name=&quot;QrcodeServlet&quot;, urlPatterns=&quot;/servlet/qrcode&quot;)public class QrcodeServlet extends HttpServlet implements Serializable&#123; &#125; Filter 1234@WebFilterpublic class LogFilter implements Filter &#123; &#125; @ServletComponentScan 注解@ComponentScan Autowired 的加载规则@Autowired 查找被注解的变量类型，找到所有此类型的构建或此类型子类的构建。 如果一个也没有找到，看required参数，false则用null，true则失败（默认）。 如果仅找到一个，则装载这个构件。 如果找到多个，且只有一个有@Primary注解，使用Primary的。 如果不符合上述条件，失败。 @Autowired @Qualifier 如果属性既有Autowired注解又有Qualifier注解 在构件中查找名字为Qualifier中指定的名字的注解。 在构件上指定名字的方法有两个，@Service(“这里写名字”)，@Qualifier(“这里写名字”)。 API 的版本客户端传递版本信息方式 URL RequestHeader URL 部署，通过修改NGINX配置，不同域名，不同前缀。 修改application.yml中的contextPath，server.servlet.contextPath:/tutorial-v2 修改@RequestMapping中的参数，例如，@RequestMapping(“/v1/tvseries”) 增加request的参数，例如：/tvseries?version=2 Request Header 自定义request header，例如：Version:2 使用Accept Accept:application/vnd.tutorial.v2 + json 自定义 RequestMappingHandlerMapping 自定义ApiVersion注解 org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping 定制Spring REST的错误返回信息Controller中单独处理 把返回值改成ResponseEntity T为要返回的内容 通过ResponseEntity来设置返回的HttpResponse状态码 全局的异常处理 12345678@RestControllerAdvicepublic class ExceptionHandler &#123; @ExceptionHandler(Throwable.class) @ResponseBody ResponseEntity&lt;Object&gt; handleControllerException(Throwable ex, WebRequest request) &#123; //处理异常，并设置给客户端反馈的信息 &#125;&#125;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[赠药山高僧惟俨二首]]></title>
    <url>%2F2018%2F12%2F23%2F%E8%B5%A0%E8%8D%AF%E5%B1%B1%E9%AB%98%E5%83%A7%E6%83%9F%E4%BF%A8%E4%BA%8C%E9%A6%96%2F</url>
    <content type="text"><![CDATA[练得身形如鹤形，千株松下两函经。我来问道无馀说，云在青霄水在瓶。 选得幽居惬野情，终年无送亦无迎。有时直上孤峰顶，月下披云啸一声。]]></content>
      <categories>
        <category>Tao</category>
      </categories>
      <tags>
        <tag>Tao</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F12%2F22%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
